{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f3aeb41687a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mURL2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"&q=%3Arelevance%3Azone%3Abeautynhealth%3Astreet%3Amain%3A\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/Applications/chromedriver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mWebDriverException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not connect to the Service %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Create dataframe\n",
    "df=pd.DataFrame()\n",
    "\n",
    "#source URL\n",
    "URL= \"https://www.hktvmall.com/hktv/en/main/search?page=0&q=%3Arelevance%3Azone%3Abeautynhealth%3Astreet%3Amain%3A\"\n",
    "URL1=\"https://www.hktvmall.com/hktv/en/main/search?page=\"\n",
    "URL2=\"&q=%3Arelevance%3Azone%3Abeautynhealth%3Astreet%3Amain%3A\"\n",
    "\n",
    "#Run selenium webdriver\n",
    "driver = webdriver.Chrome(executable_path=\"/Applications/chromedriver\")\n",
    "driver.get(URL)\n",
    "time.sleep(5)\n",
    "html = driver.page_source\n",
    "soup=BeautifulSoup(html, \"html.parser\")\n",
    "URL_iter=0\n",
    "\n",
    "# extract relevant information\n",
    "while int(URL_iter)<867:\n",
    "    for item in soup.find_all(class_=\"info-wrapper\"):\n",
    "        #Raw info\n",
    "        try:\n",
    "            p_raw=item.find(class_=\"brand-product-name\").text\n",
    "            print(\"Raw Info:\", p_raw)\n",
    "        except:\n",
    "            p_raw=str(np.nan)\n",
    "            print(\"Raw Info:\", p_raw)\n",
    "        #Brand\n",
    "        try:\n",
    "            p_brand=re.match(\"^(.*?)\\s\\-\\s\", p_raw).group(1)\n",
    "            print(\"Product Brand:\", p_brand)\n",
    "        except:\n",
    "            p_brand=p_raw\n",
    "            print(\"Product Brand:\", p_brand)\n",
    "        #Product Name\n",
    "        try:\n",
    "            p_item=re.match(\"^(?:.*)\\s\\-\\s(.*)\", p_raw).group(1)\n",
    "            print(\"Product Name:\", p_item)\n",
    "\n",
    "        except:\n",
    "            p_item=p_raw\n",
    "            print(\"Product Name:\", p_item)\n",
    "        #Number of Sales\n",
    "        try:\n",
    "            p_sales=item.find(class_=\"salesNumber-container\").text.replace(\"+ Sold\", \"\")\n",
    "            print(\"Sales:\", p_sales)\n",
    "        except:\n",
    "            p_sales=np.nan\n",
    "            print(\"Sales:\", p_sales)\n",
    "        #Original Price\n",
    "        try:\n",
    "            p_oprice=item.find(class_=\"promotional\").span.text\n",
    "            p_oprice2=re.match(\"^(?:.*\\$)(.*)\", p_oprice).group(1)\n",
    "            print(\"Original Price:\", p_oprice2)\n",
    "        except:\n",
    "            p_oprice=np.nan \n",
    "            print(\"Original Price:\", p_oprice)       \n",
    "        #Discount Price\n",
    "        try:\n",
    "            p_dprice=item.find(class_=\"price\").span.text.replace(\"$ \", \"\")\n",
    "            print(\"Discount Price:\", p_dprice)\n",
    "        except:\n",
    "            p_dprice=np.nan\n",
    "            print(\"Discount Price:\", p_dprice)\n",
    "        #Promotion tag\n",
    "        try:\n",
    "            promo=item.find(class_=\"deliveryLabelText\").text\n",
    "            print(\"Promo Tag:\", promo)\n",
    "        except:\n",
    "            promo=np.nan\n",
    "            print(\"Promo Tag:\", promo)\n",
    "        #Rating\n",
    "        try:\n",
    "            rating=item.find(class_=\"star_container\")[\"data-rating\"]\n",
    "            print(\"Rating:\", rating)\n",
    "        except:\n",
    "            rating=np.nan\n",
    "            print(\"Rating:\", rating)\n",
    "        #Number of reviews\n",
    "        try:\n",
    "            review=item.find(class_=\"review-number\").text.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            print(\"Review:\", review)\n",
    "        except:\n",
    "            review=np.nan\n",
    "            print(\"Review:\", review)\n",
    "        #Vendor name\n",
    "        try:\n",
    "            vendor=item.find(class_=\"store-name-label\").text\n",
    "            print(\"Vendor:\", vendor)\n",
    "        except:\n",
    "            vendor=np.nan\n",
    "            print(\"Vendor:\", vendor)\n",
    "        #Category code\n",
    "        try:\n",
    "            category=item.find(class_=\"sepaButton add-to-cart-button\")[\"data-category\"]\n",
    "            print(\"Product Category Code:\", category)\n",
    "        except:\n",
    "            category=str(np.nan)\n",
    "            print(\"Product Category Code:\", category)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "#save to dataframe\n",
    "        df=df.append({\"Raw Info\":p_raw, \"Product Brand\":p_brand, \"Product Name\":p_item, \"Sales\":p_sales, \"Original Price\":p_oprice2, \"Discount price\":p_dprice, \"Promo Tag\":promo, \"Rating\":rating, \"Review\":review, \"Vendor\":vendor, \"Product Category Code\":category}, ignore_index=True)\n",
    "    \n",
    "#load next page\n",
    "    URL_no=re.findall(\"\\?page\\=(\\d*)\\&q\\=.*\",URL)\n",
    "    URL_iter=str(int(URL_no[0])+1)\n",
    "\n",
    "    URL = URL1+URL_iter+URL2\n",
    "    nextlink=URL1+URL_iter+URL2\n",
    "    print(nextlink)\n",
    "\n",
    "    subhtml=driver.get(nextlink)\n",
    "    time.sleep(5)\n",
    "    subhtml=driver.page_source\n",
    "    soup=BeautifulSoup(subhtml, \"html.parser\")\n",
    "#save dataframe to csv\n",
    "df.to_csv(\"hktvmall_skincare_females_and_males.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ]
}